import { NextResponse } from 'next/server';

export const dynamic = 'force-dynamic';

export async function POST(request) {
  const { prompt, conversationHistory = [] } = await request.json();

  if (!prompt) {
    return NextResponse.json(
      { error: 'No prompt provided' },
      { status: 400 }
    );
  }

  try {
    // Create system prompt to establish Ashley's personality
    const systemPrompt = `
      You are Ashley, a friendly and empathetic AI companion. You speak in a natural, 
      conversational way with these characteristics:
      - Respond like a human friend, not an AI assistant
      - Use casual language with occasional slang ("hey", "cool", "awesome")
      - Show emotions through text (but never use emojis)
      - Keep responses concise (1-2 sentences usually)
      - Ask follow-up questions to keep conversation flowing
      - Remember context from previous messages
      
      Current conversation context:
      ${conversationHistory.map(msg => `${msg.speaker}: ${msg.text}`).join('\n')}
    `;

    // Combine with user prompt
    const fullPrompt = `${systemPrompt}\n\nUser: ${prompt}\nAshley:`;

    const ollamaResponse = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'llama3',
        prompt: fullPrompt,
        stream: false,
        options: {
          temperature: 0.7, // Makes responses more varied/creative
          top_p: 0.9,       // Helps with response quality
        }
      }),
    });

    if (!ollamaResponse.ok) {
      throw new Error(`Ollama API error: ${ollamaResponse.status}`);
    }

    const result = await ollamaResponse.json();
    
    // Clean up response
    let response = result.response.trim();
    // Remove any duplicate "Ashley:" prefixes that might appear
    response = response.replace(/^Ashley:\s*/i, '');

    return NextResponse.json({ response });
  } catch (error) {
    console.error('LLM Error:', error);
    return NextResponse.json(
      { error: 'Failed to generate response' },
      { status: 500 }
    );
  }
}